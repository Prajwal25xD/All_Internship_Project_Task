{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b6dbebd",
   "metadata": {},
   "source": [
    "# Image Captioning Notebook\n",
    "This notebook explains the full workflow behind the image caption generator, including model loading, preprocessing, feature extraction, and caption generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe34fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53642b1b",
   "metadata": {},
   "source": [
    "## Load Tokenizer, Models, and Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all():\n",
    "    with open('tokenizer.pkl', 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    max_length = 36\n",
    "\n",
    "    input_img_features = Input(shape=(2048,), name=\"image_input\")\n",
    "    feat_model = Dropout(0.4)(input_img_features)\n",
    "    feat_model = Dense(256, activation='relu')(feat_model)\n",
    "\n",
    "    input_text = Input(shape=(max_length,), name=\"text_input\")\n",
    "    text_model = Embedding(vocab_size, 256, mask_zero=True)(input_text)\n",
    "    text_model = Dropout(0.4)(text_model)\n",
    "    text_model = LSTM(256)(text_model)\n",
    "\n",
    "    decoder = add([feat_model, text_model])\n",
    "    decoder = Dense(256, activation='relu')(decoder)\n",
    "    output = Dense(vocab_size, activation='softmax')(decoder)\n",
    "\n",
    "    model = Model(inputs=[input_img_features, input_text], outputs=output)\n",
    "    model.load_weights(\"image_captioning_model_weights.weights.h5\")\n",
    "\n",
    "    base_model = InceptionV3(weights='imagenet')\n",
    "    feature_extractor = Model(base_model.input, base_model.layers[-2].output)\n",
    "\n",
    "    return model, feature_extractor, tokenizer, max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48168bf",
   "metadata": {},
   "source": [
    "## Preprocess Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pil_image(image_pil):\n",
    "    image = image_pil.resize((299, 299))\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10646d4",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ac559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_pil(image_pil, feature_extractor):\n",
    "    img_preprocessed = preprocess_pil_image(image_pil)\n",
    "    features = feature_extractor.predict(img_preprocessed, verbose=0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9b263",
   "metadata": {},
   "source": [
    "## Convert Token ID to Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa768b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31648e30",
   "metadata": {},
   "source": [
    "## Generate Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b794b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(model, tokenizer, image_features, max_length):\n",
    "    in_text = '<start>'\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length, padding='post')\n",
    "        yhat = model.predict([image_features, sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == '<end>':\n",
    "            break\n",
    "    return in_text.replace('<start>', '').replace('<end>', '').strip()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
